{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup\n",
    "1. In colab: Go to \"Runtime\" -> \"Change runtime type\" -> Select \"T4 GPU\"\n",
    "2. Install TerraTorch"
   ],
   "id": "b4bacc318390456b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install terratorch==0.99.8 gdown tensorboard",
   "id": "W_4z81Fn9RET",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a",
   "metadata": {
    "id": "2e8c1961-311b-49e0-b6ea-2867b44cb47a"
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import gdown\n",
    "import terratorch\n",
    "import albumentations\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from terratorch.datamodules import GenericNonGeoSegmentationDataModule"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "3. Download the dataset from Google Drive",
   "id": "917b65b8e7cd7d65"
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.isfile('sen1floods11_v1.1.tar.gz'):\n",
    "    gdown.download(\"https://drive.google.com/uc?id=1lRw3X7oFNq_WyzBO6uyUJijyTuYm23VS\")\n",
    "    !tar -xzvf sen1floods11_v1.1.tar.gz"
   ],
   "metadata": {
    "id": "dw5-9A4A4OmI",
    "collapsed": true
   },
   "id": "dw5-9A4A4OmI",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494",
   "metadata": {
    "id": "35ba4d58-8ff6-4f9c-bfb1-a70376f80494"
   },
   "source": [
    "## Sen1Floods11 Dataset\n",
    "\n",
    "Lets start with analysing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "e3854bdb-17a4-43c8-bfa8-822b44fd59c3",
   "metadata": {
    "id": "e3854bdb-17a4-43c8-bfa8-822b44fd59c3"
   },
   "source": [
    "dataset_path = Path('sen1floods11_v1.1')\n",
    "!ls \"sen1floods11_v1.1/data\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!ls \"sen1floods11_v1.1/data/S2L1CHand/\" | head",
   "id": "87d91245594c607d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc",
   "metadata": {
    "id": "735803b1-a4bf-427f-a1e6-5ac755af33fc"
   },
   "source": [
    "# TerraTorch provides generic data modules that work directly with PyTorch Lightning\n",
    "datamodule = terratorch.datamodules.GenericNonGeoSegmentationDataModule(\n",
    "    batch_size=8,\n",
    "    num_workers=2,\n",
    "    num_classes=2,\n",
    "\n",
    "    # Define data paths\n",
    "    train_data_root=dataset_path / 'data/S2L1CHand',\n",
    "    train_label_data_root=dataset_path / 'data/LabelHand',\n",
    "    val_data_root=dataset_path / 'data/S2L1CHand',\n",
    "    val_label_data_root=dataset_path / 'data/LabelHand',\n",
    "    test_data_root=dataset_path / 'data/S2L1CHand',\n",
    "    test_label_data_root=dataset_path / 'data/LabelHand',\n",
    "\n",
    "    # Define splits as all samples are saved in the same folder\n",
    "    train_split=dataset_path / 'splits/flood_train_data.txt',\n",
    "    val_split=dataset_path / 'splits/flood_valid_data.txt',\n",
    "    test_split=dataset_path / 'splits/flood_test_data.txt',\n",
    "    \n",
    "    # Define suffix\n",
    "    img_grep='*_S2Hand.tif',\n",
    "    label_grep='*_LabelHand.tif',\n",
    "    \n",
    "    train_transform=[\n",
    "        albumentations.D4(), # Random flips and rotation\n",
    "        albumentations.pytorch.transforms.ToTensorV2(),\n",
    "    ],\n",
    "    val_transform=None,  # Using ToTensor() by default\n",
    "    test_transform=None,\n",
    "    \n",
    "    # Define bands in the data and which one you want to use (optional)\n",
    "    dataset_bands=[\n",
    "      \"COASTAL_AEROSOL\",\n",
    "      \"BLUE\",\n",
    "      \"GREEN\",\n",
    "      \"RED\",\n",
    "      \"RED_EDGE_1\",\n",
    "      \"RED_EDGE_2\",\n",
    "      \"RED_EDGE_3\",\n",
    "      \"NIR_BROAD\",\n",
    "      \"NIR_NARROW\",\n",
    "      \"CIRRUS\",\n",
    "      \"SWIR_1\",\n",
    "      \"SWIR_2\",\n",
    "    ],\n",
    "    output_bands=[\n",
    "      \"BLUE\",\n",
    "      \"GREEN\",\n",
    "      \"RED\",\n",
    "      \"NIR_NARROW\",\n",
    "      \"SWIR_1\",\n",
    "      \"SWIR_2\", \n",
    "    ],\n",
    "    \n",
    "    # Define standardization values for the output_bands\n",
    "    means=[\n",
    "      0.11076498225107874,\n",
    "      0.13456047562676646,\n",
    "      0.12477149645635542,\n",
    "      0.3248933937526503,\n",
    "      0.23118412840904512,\n",
    "      0.15624583324071273,\n",
    "    ],\n",
    "    stds=[\n",
    "      0.15469174852002912,\n",
    "      0.13070592427323752,\n",
    "      0.12786689586224442,\n",
    "      0.13925781946803198,\n",
    "      0.11303782829438778,\n",
    "      0.10207461132314981,\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Setup train and val datasets\n",
    "datamodule.setup(\"fit\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# checking datasets train split size\n",
    "train_dataset = datamodule.train_dataset\n",
    "len(train_dataset)"
   ],
   "id": "08644e71-d82f-426c-b0c1-79026fccb578",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# checking datasets validation split size\n",
    "val_dataset = datamodule.val_dataset\n",
    "len(val_dataset)"
   ],
   "id": "b7062ddc-a3b7-4378-898c-41abcdf2ee3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting a few samples\n",
    "val_dataset.plot(val_dataset[0])\n",
    "val_dataset.plot(val_dataset[9])\n",
    "val_dataset.plot(val_dataset[11])"
   ],
   "id": "3a1da2ad-a797-4f4a-ad1a-cd10f9addb01",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79",
   "metadata": {
    "id": "ede1c1c6-9f60-4510-a2da-572c55d03f79"
   },
   "source": [
    "# checking datasets testing split size\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "len(test_dataset)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# TerraTorch model factory",
   "id": "cf0453502fb0bf62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# TerraTorch includes meta registries for all model components \n",
    "from terratorch.registry import BACKBONE_REGISTRY, TERRATORCH_BACKBONE_REGISTRY, TERRATORCH_DECODER_REGISTRY"
   ],
   "id": "d970183baaea88cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(TERRATORCH_BACKBONE_REGISTRY)[:5]",
   "id": "f4109f8f262cc5f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "list(TERRATORCH_DECODER_REGISTRY)",
   "id": "9a51fdde4e1e5d1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build PyTorch model for custom pipeline\n",
    "model = BACKBONE_REGISTRY.build(\"prithvi_eo_v2_300_tl\", pretrained=True)"
   ],
   "id": "56bc7fa971e02793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model",
   "id": "9fcb50e133f20cd7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-tune Prithvi via PyTorch Lightning",
   "id": "654a30ddef8ed5a"
  },
  {
   "cell_type": "code",
   "id": "ae69d39a-857a-4392-b058-0f4b518edf6e",
   "metadata": {
    "scrolled": true,
    "id": "ae69d39a-857a-4392-b058-0f4b518edf6e"
   },
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"output/sen1floods11/checkpoints/\",\n",
    "    mode=\"max\",\n",
    "    monitor=\"val/Multiclass_Jaccard_Index\", # Variable to monitor\n",
    "    filename=\"best-{epoch:02d}\",\n",
    ")\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    devices=1, # Deactivate multi-gpu because it often fails in notebooks\n",
    "    precision='16-mixed',  # Speed up training\n",
    "    num_nodes=1,\n",
    "    logger=True,  # Uses TensorBoard by default\n",
    "    max_epochs=5, # For demos\n",
    "    log_every_n_steps=1,\n",
    "    enable_checkpointing=True,\n",
    "    callbacks=[checkpoint_callback, pl.callbacks.RichProgressBar()],\n",
    "    default_root_dir=\"output/sen1floods11/\",\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = terratorch.tasks.SemanticSegmentationTask(\n",
    "    model_factory=\"EncoderDecoderFactory\",\n",
    "    model_args={\n",
    "        # Backbone\n",
    "        \"backbone\": \"prithvi_eo_v2_300_tl\", # Model can be either prithvi_eo_v1_100, prithvi_eo_v2_300, prithvi_eo_v2_300_tl, prithvi_eo_v2_600, prithvi_eo_v2_600_tl\n",
    "        \"backbone_pretrained\": True,\n",
    "        \"backbone_num_frames\": 1, # 1 is the default value\n",
    "        \"backbone_img_size\": 512, # if not provided: interpolate pos embedding from 224 pre-training which also works well\n",
    "        \"backbone_bands\": [\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"],\n",
    "        \"backbone_coords_encoding\": [], # use [\"time\", \"location\"] for time and location metadata\n",
    "        \n",
    "        # Necks \n",
    "        \"necks\": [\n",
    "            {\n",
    "                \"name\": \"SelectIndices\",\n",
    "                # \"indices\": [2, 5, 8, 11] # indices for prithvi_eo_v1_100\n",
    "                \"indices\": [5, 11, 17, 23] # indices for prithvi_eo_v2_300\n",
    "                # \"indices\": [7, 15, 23, 31] # indices for prithvi_eo_v2_600\n",
    "            },\n",
    "            {\"name\": \"ReshapeTokensToImage\",},\n",
    "            {\"name\": \"LearnedInterpolateToPyramidal\"}            \n",
    "        ],\n",
    "        \n",
    "        # Decoder\n",
    "        \"decoder\": \"UNetDecoder\",\n",
    "        \"decoder_channels\": [512, 256, 128, 64],\n",
    "        \n",
    "        # Head\n",
    "        \"head_dropout\": 0.1,\n",
    "        \"num_classes\": 2,\n",
    "    },\n",
    "    \n",
    "    loss=\"dice\",\n",
    "    optimizer=\"AdamW\",\n",
    "    lr=1e-4,\n",
    "    ignore_index=-1,\n",
    "    freeze_backbone=True, # Speeds up fine-tuning\n",
    "    freeze_decoder=False,\n",
    "    plot_on_val=True,\n",
    "    class_names=['no water', 'water']  # optionally define class names\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ],
   "id": "ca03ce8977006bb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=datamodule)"
   ],
   "id": "ff284062edfce308",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "best_ckpt_path = \"output/sen1floods11/checkpoints/best-epoch=01.ckpt\"",
   "id": "a0d51d08802df9e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "35a77263-5308-4781-a17f-a35e62ca1875",
   "metadata": {
    "scrolled": true,
    "id": "35a77263-5308-4781-a17f-a35e62ca1875"
   },
   "source": "trainer.test(model, datamodule=datamodule, ckpt_path=best_ckpt_path)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e015fe0-88ee-46cf-b972-f8cb9d361536",
   "metadata": {
    "id": "1e015fe0-88ee-46cf-b972-f8cb9d361536",
    "outputId": "c7c06228-e634-4608-cb0e-617d003fea46",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "# now we can use the model for predictions and plotting!\n",
    "model = terratorch.tasks.SemanticSegmentationTask.load_from_checkpoint(\n",
    "    best_ckpt_path,\n",
    "    model_factory=model.hparams.model_factory,\n",
    "    model_args=model.hparams.model_args,\n",
    ")\n",
    "\n",
    "test_loader = datamodule.test_dataloader()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    images = batch[\"image\"].to(model.device)\n",
    "    masks = batch[\"mask\"].numpy()\n",
    "\n",
    "    outputs = model(images)\n",
    "    preds = torch.argmax(outputs.output, dim=1).cpu().numpy()\n",
    "\n",
    "for i in range(5):\n",
    "    sample = {key: batch[key][i] for key in batch}\n",
    "    sample[\"prediction\"] = preds[i]\n",
    "    test_dataset.plot(sample)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine-tuning via CLI\n",
    "\n",
    "You might want to restart the session to free up GPU memory."
   ],
   "id": "80e7cf70f5e06c3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Download config\n",
    "!wget wget https://raw.githubusercontent.com/ibm/TerraTorch/refs/heads/main/examples/tutorial/configs/prithvi_v2_eo_300_tl_unet_sen1floods11.yaml"
   ],
   "id": "38b357340b087bc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Run fine-tuning\n",
    "!terratorch fit -c prithvi_v2_eo_300_tl_unet_sen1floods11.yaml"
   ],
   "id": "fd1c41843f46666f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
